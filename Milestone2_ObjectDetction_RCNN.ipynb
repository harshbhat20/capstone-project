{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1amf4Z_lb3d7"
   },
   "source": [
    "## Milestone - 2 : Training and Tuning models for Pneumonia Detection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XAhQC3PgiMu",
    "outputId": "79fc1123-5b3b-455c-822f-564b89414311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FO8gXP6bbD-y"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J3Wwgq1_kR3r"
   },
   "outputs": [],
   "source": [
    "# Loading and splitting data\n",
    "data_dir = 'Dataset/stage_2_train_images'\n",
    "labels_df = pd.read_csv('Dataset/stage_2_train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TyrtXcDTcFTq"
   },
   "outputs": [],
   "source": [
    "#Using a datagenerator to optimize memory usage and keep the image size at 512*512\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "\n",
    "class DicomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, data_dir, batch_size=4, img_size=512, shuffle=True, subset='training'):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.subset = subset\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        return self.__data_generation(batch_df)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_df):\n",
    "        # Vectorized processing for faster performance\n",
    "        file_paths = batch_df['patientId'].apply(lambda x: os.path.join(self.data_dir, f\"{x}.dcm\")).values\n",
    "        labels = batch_df['Target'].values\n",
    "\n",
    "        X = np.array([self._process_dicom(file_path) for file_path in file_paths])\n",
    "        y = np.array(labels, dtype=int)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _process_dicom(self, file_path):\n",
    "        # Efficient single file processing\n",
    "        ds = pydicom.dcmread(file_path)\n",
    "        img = ds.pixel_array\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))  # Resize\n",
    "        img = img / 255.0  # Normalize\n",
    "        img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "        return img\n",
    "\n",
    "# Loading and splitting data\n",
    "data_dir = 'Dataset/stage_2_train_images'\n",
    "labels_df = pd.read_csv('Dataset/stage_2_train_labels.csv')\n",
    "# data_dir = 'https://drive.google.com/file/d/1-2AEqHphM2n-M9L6i9SYG4E3hGkRawth/view?usp=drive_link'\n",
    "\n",
    "# Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate generators\n",
    "train_generator = DicomDataGenerator(train_df, data_dir, batch_size=8, img_size=512, shuffle=True, subset='training')\n",
    "val_generator = DicomDataGenerator(val_df, data_dir, batch_size=8, img_size=512, shuffle=False, subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z1EIgdsYcGuK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4oB2ZKEicJmh"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 4\n",
    "img_size = 512\n",
    "\n",
    "# Data directories\n",
    "data_dir = 'Dataset/stage_2_train_images'\n",
    "\n",
    "# Initialize generators\n",
    "train_generator = DicomDataGenerator(train_df, data_dir, batch_size=batch_size, img_size=img_size, subset='training')\n",
    "val_generator = DicomDataGenerator(val_df, data_dir, batch_size=batch_size, img_size=img_size, subset='validation')\n",
    "test_generator = DicomDataGenerator(test_df, data_dir, batch_size=batch_size, img_size=img_size, subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "s3wd5hetcOHe",
    "outputId": "291df25b-ea2d-4288-d96d-fd3715166ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">492032</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">251,920,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m492032\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │   \u001b[38;5;34m251,920,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">252,014,081</span> (961.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m252,014,081\u001b[0m (961.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">252,014,081</span> (961.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m252,014,081\u001b[0m (961.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Basic CNN Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define input image size\n",
    "input_shape = (img_size, img_size, 1)  # Grayscale images\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, name='Conv1'),\n",
    "    MaxPooling2D((2, 2), name='Pool1'),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu', name='Conv2'),\n",
    "    MaxPooling2D((2, 2), name='Pool2'),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu', name='Conv3'),\n",
    "    MaxPooling2D((2, 2), name='Pool3'),\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Flatten(name='Flatten'),\n",
    "    Dense(512, activation='relu', name='FC1'),\n",
    "    Dense(1, activation='sigmoid', name='Output')  # For binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZuK6EvFcRul",
    "outputId": "c5c220f0-cc94-4dc9-9f7b-688c654f7f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3392s\u001b[0m 623ms/step - accuracy: 0.7448 - loss: 0.5303 - val_accuracy: 0.7437 - val_loss: 0.5180\n",
      "Epoch 2/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18169s\u001b[0m 3s/step - accuracy: 0.7676 - loss: 0.4818 - val_accuracy: 0.7735 - val_loss: 0.4730\n",
      "Epoch 3/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24410s\u001b[0m 4s/step - accuracy: 0.7877 - loss: 0.4539 - val_accuracy: 0.7896 - val_loss: 0.4613\n",
      "Epoch 4/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4790s\u001b[0m 880ms/step - accuracy: 0.8182 - loss: 0.4040 - val_accuracy: 0.7813 - val_loss: 0.4859\n",
      "Epoch 5/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4328s\u001b[0m 795ms/step - accuracy: 0.8523 - loss: 0.3390 - val_accuracy: 0.7929 - val_loss: 0.4972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x32d439e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=5, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "scIrVE_BcXKb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 67ms/step - accuracy: 0.8781 - loss: 0.2934\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.7829 - loss: 0.5453\n",
      "\u001b[1m1512/1512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 67ms/step - accuracy: 0.7827 - loss: 0.4984\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training, validation, and testing data\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "test_loss, test_acc = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zFI6j_ovca3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Model, Training Loss, Training Accuracy, Validation Loss, Validation Accuracy, Testing Loss, Testing Accuracy]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Testing Loss</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN Base Model</td>\n",
       "      <td>0.291211</td>\n",
       "      <td>0.880066</td>\n",
       "      <td>0.497216</td>\n",
       "      <td>0.79289</td>\n",
       "      <td>0.504358</td>\n",
       "      <td>0.78432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Training Loss  Training Accuracy  Validation Loss  \\\n",
       "0  CNN Base Model       0.291211           0.880066         0.497216   \n",
       "\n",
       "   Validation Accuracy  Testing Loss  Testing Accuracy  \n",
       "0              0.79289      0.504358           0.78432  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe with evaluation metrics of each model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    'Model',\n",
    "    'Training Loss', 'Training Accuracy',\n",
    "    'Validation Loss', 'Validation Accuracy',\n",
    "    'Testing Loss', 'Testing Accuracy'\n",
    "])\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Create a dictionary with the metrics\n",
    "model_metrics = {\n",
    "    'Model': \"CNN Base Model\",\n",
    "    'Training Loss': train_loss, 'Training Accuracy': train_acc,\n",
    "    'Validation Loss': val_loss, 'Validation Accuracy': val_acc,\n",
    "    'Testing Loss': test_loss, 'Testing Accuracy': test_acc,\n",
    "\n",
    "}\n",
    "\n",
    "# Append the metrics to the DataFrame\n",
    "model_metrics_df = pd.DataFrame([model_metrics])\n",
    "metrics_df = pd.concat([metrics_df,model_metrics_df], ignore_index=True)\n",
    "\n",
    "# Print the DataFrame to check the added metrics\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8Hn8mOtscd_c"
   },
   "outputs": [],
   "source": [
    "metrics_df.to_csv('accuracy_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ydT7Anb6cgPo"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('cnn_base_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk3gaA8jckSV"
   },
   "source": [
    "Above basic CNN model gives us a testing accuracy of about 80%.To improve the testing accuracy of your CNN model, we can enhance the architecture and introduce regularization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "50vnjyK4cppo"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def create_model(input_shape=(512, 512, 1)):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WxhRjPDYcsMs"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7JsMazyXcuZE"
   },
   "outputs": [],
   "source": [
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QJvT1JKEcwpj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4097s\u001b[0m 753ms/step - accuracy: 0.6668 - loss: 16.9127 - val_accuracy: 0.6763 - val_loss: 1.6313\n",
      "Epoch 2/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3933s\u001b[0m 723ms/step - accuracy: 0.6751 - loss: 1.6812 - val_accuracy: 0.6763 - val_loss: 0.9176\n",
      "Epoch 3/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3999s\u001b[0m 735ms/step - accuracy: 0.7326 - loss: 0.7163 - val_accuracy: 0.7586 - val_loss: 0.5818\n",
      "Epoch 4/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4052s\u001b[0m 745ms/step - accuracy: 0.7458 - loss: 0.6089 - val_accuracy: 0.7565 - val_loss: 0.5596\n",
      "Epoch 5/5\n",
      "\u001b[1m5441/5441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4256s\u001b[0m 782ms/step - accuracy: 0.7546 - loss: 0.5908 - val_accuracy: 0.7764 - val_loss: 0.5414\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1248997019.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    return history\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=5,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0tXBO83czYa"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on training, validation, and testing data\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "test_loss, test_acc = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anV3obdVc1o6"
   },
   "outputs": [],
   "source": [
    "new_metrics = {\n",
    "    'Model': \"Regularized CNN Model\",\n",
    "    'Training Loss': train_loss, 'Training Accuracy': train_acc,\n",
    "    'Validation Loss': val_loss, 'Validation Accuracy': val_acc,\n",
    "    'Testing Loss': test_loss, 'Testing Accuracy': test_acc\n",
    "}\n",
    "new_metrics_df = pd.DataFrame([new_metrics])\n",
    "\n",
    "# Load the existing CSV file\n",
    "csv_file = 'accuracy_metrics.csv'\n",
    "\n",
    "existing_metrics = pd.read_csv(csv_file)\n",
    "\n",
    "# Append the new metrics to the existing DataFrame\n",
    "updated_metrics = pd.concat([existing_metrics, new_metrics_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "updated_metrics.to_csv(csv_file, index=False)\n",
    "\n",
    "# Save the model\n",
    "model.save('regularised_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPm5BspIc4UF"
   },
   "outputs": [],
   "source": [
    "print(updated_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCdREb-nc63X"
   },
   "source": [
    "### Transfer Learning - VGG16 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu_3Ij84c-ei"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def create_vgg16_model(input_shape=(512, 512, 1)):\n",
    "    # Load the VGG16 model pre-trained on ImageNet, without the top (fully connected) layers\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "    # Convert grayscale to 3 channels by duplicating the single channel\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(3, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    # Use the output of the base model as the new input\n",
    "    x = base_model(x)\n",
    "\n",
    "    # Add new fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "ty3Rcf7XdBHl",
    "outputId": "a80aaac9-b3c1-46c8-d394-32ca8837895e"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = create_vgg16_model()\n",
    "\n",
    "## Callbacks for early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('vgg16_best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyW31ZcLdDx8"
   },
   "outputs": [],
   "source": [
    "new_metrics = {\n",
    "    'Model': \"VGG16 Model\",\n",
    "    'Training Loss': train_loss, 'Training Accuracy': train_acc,\n",
    "    'Validation Loss': val_loss, 'Validation Accuracy': val_acc,\n",
    "    'Testing Loss': test_loss, 'Testing Accuracy': test_acc\n",
    "}\n",
    "new_metrics_df = pd.DataFrame([new_metrics])\n",
    "\n",
    "# Load the existing CSV file\n",
    "csv_file = 'accuracy_metrics.csv'\n",
    "\n",
    "existing_metrics = pd.read_csv(csv_file)\n",
    "\n",
    "# Append the new metrics to the existing DataFrame\n",
    "updated_metrics = pd.concat([existing_metrics, new_metrics_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "updated_metrics.to_csv(csv_file, index=False)\n",
    "\n",
    "# Save the model\n",
    "model.save('VGG16_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVL3WjdCdGQD"
   },
   "outputs": [],
   "source": [
    "print(updated_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNVIZ0UUdHOX"
   },
   "source": [
    "### Transfer Learning - ResNet50 Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXhN4yFKdKkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def create_resnet50_model(input_shape=(512, 512, 1)):\n",
    "    # Load the resnet50 model pre-trained on ImageNet, without the top (fully connected) layers\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet',input_shape =(512, 512, 3))\n",
    "\n",
    "    # Convert grayscale to 3 channels by duplicating the single channel\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(3, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    # Use the output of the base model as the new input\n",
    "    x = base_model(x)\n",
    "\n",
    "    # Add new fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUVZy03ldP7W"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = create_resnet50_model()\n",
    "\n",
    "## Callbacks for early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('resnet50_best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbsnq4a9dUdb"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on training, validation, and testing data\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "test_loss, test_acc = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdKCQiuxdW90"
   },
   "outputs": [],
   "source": [
    "new_metrics = {\n",
    "    'Model': \"ResNet50 Model\",\n",
    "    'Training Loss': train_loss, 'Training Accuracy': train_acc,\n",
    "    'Validation Loss': val_loss, 'Validation Accuracy': val_acc,\n",
    "    'Testing Loss': test_loss, 'Testing Accuracy': test_acc\n",
    "}\n",
    "new_metrics_df = pd.DataFrame([new_metrics])\n",
    "\n",
    "# Load the existing CSV file\n",
    "csv_file = 'accuracy_metrics.csv'\n",
    "\n",
    "existing_metrics = pd.read_csv(csv_file)\n",
    "\n",
    "# Append the new metrics to the existing DataFrame\n",
    "updated_metrics = pd.concat([existing_metrics, new_metrics_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "updated_metrics.to_csv(csv_file, index=False)\n",
    "\n",
    "# Save the model\n",
    "model.save('ResNet50_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4DJIGLKdfKs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('accuracy_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkLUYpPvdqP4"
   },
   "source": [
    "### Object Detection with Mask RCNN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIfeiCsRdtwt"
   },
   "outputs": [],
   "source": [
    "# setting up the input directories and working directory to save models\n",
    "# and variables\n",
    "\n",
    "DATA_DIR = 'input'\n",
    "ROOT_DIR = 'working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Qv0XaLwdx-Z"
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN from the above implementation\n",
    "\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jOk8lMMd0YS"
   },
   "outputs": [],
   "source": [
    "# training and testing directory of images\n",
    "\n",
    "train_dicom_dir = os.path.join(DATA_DIR, 'stage_2_train_images')\n",
    "test_dicom_dir = os.path.join(DATA_DIR, 'stage_2_test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tNkP8YQd3JD"
   },
   "outputs": [],
   "source": [
    "# list of dicom image paths and filenames\n",
    "\n",
    "def get_dicom_fps(dicom_dir):\n",
    "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
    "    return list(set(dicom_fps))\n",
    "\n",
    "\n",
    "# list of image filenames and annotations dictionary\n",
    "def parse_dataset(dicom_dir, anns):\n",
    "    image_fps = get_dicom_fps(dicom_dir)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows():\n",
    "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
    "        image_annotations[fp].append(row)\n",
    "    return image_fps, image_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK6DmFUed6iz"
   },
   "outputs": [],
   "source": [
    "# Configuring the matterport Mask RCNN framework for Pneumonia Detection\n",
    "# Customising parameters in the base 'config' class\n",
    "\n",
    "class DetectorConfig(Config):\n",
    "    NAME = 'pneumonia'\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    BACKBONE = 'resnet50'\n",
    "\n",
    "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
    "\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "config = DetectorConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI0gRJQhd9rg"
   },
   "outputs": [],
   "source": [
    "# Loading and processing the dataset\n",
    "\n",
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "\n",
    "        # Add classes\n",
    "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
    "\n",
    "        # add images\n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations[fp]\n",
    "            self.add_image('pneumonia', image_id=i, path=fp,\n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['Target'] == 1:\n",
    "                    x = int(a['x'])\n",
    "                    y = int(a['y'])\n",
    "                    w = int(a['width'])\n",
    "                    h = int(a['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gW0rbY3eeAgV"
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "anns = pd.read_csv(os.path.join(DATA_DIR, 'stage_2_train_labels.csv'))\n",
    "anns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G2Fm-ZweDNg"
   },
   "outputs": [],
   "source": [
    "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96VmALVueG3W"
   },
   "outputs": [],
   "source": [
    "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath\n",
    "image = ds.pixel_array # get image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4_96WJpeJle"
   },
   "outputs": [],
   "source": [
    "# show dicom fields\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zsg5Hf_eL0r"
   },
   "outputs": [],
   "source": [
    "# Original image size\n",
    "\n",
    "ORIG_SIZE ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLuLBhf-eOTf"
   },
   "outputs": [],
   "source": [
    "# splitting dataset into training and validation\n",
    "\n",
    "image_fps_list = list(image_fps)\n",
    "random.seed(42)\n",
    "random.shuffle(image_fps_list)\n",
    "\n",
    "val_size = 1500\n",
    "image_fps_val = image_fps_list[:val_size]\n",
    "image_fps_train = image_fps_list[val_size:]\n",
    "\n",
    "print(len(image_fps_train), len(image_fps_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i362eV7BeQ4A"
   },
   "outputs": [],
   "source": [
    "# prepare the training dataset\n",
    "\n",
    "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZndwEpgeVO4"
   },
   "outputs": [],
   "source": [
    "# Show annotation for an image\n",
    "\n",
    "test_fp = random.choice(image_fps_train)\n",
    "image_annotations[test_fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9PLkPSZeYcJ"
   },
   "outputs": [],
   "source": [
    "# prepare the validation dataset, same as above\n",
    "\n",
    "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkRe-SSweatj"
   },
   "outputs": [],
   "source": [
    "# Load and display random sample and their bounding boxes\n",
    "\n",
    "class_ids = [0]\n",
    "while class_ids[0] == 0:  ## look for a mask\n",
    "    image_id = random.choice(dataset_train.image_ids)\n",
    "    image_fp = dataset_train.image_reference(image_id)\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "masked = np.zeros(image.shape[:2])\n",
    "for i in range(mask.shape[2]):\n",
    "    masked += image[:, :, 0] * mask[:, :, i]\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "print(image_fp)\n",
    "print(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0wT4IdgedMp"
   },
   "outputs": [],
   "source": [
    "# Image augmentation using the imgaug library\n",
    "\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.04), \"y\": (0.98, 1.04)},\n",
    "            translate_percent={\"x\": (-0.03, 0.03), \"y\": (-0.05, 0.05)},\n",
    "            rotate=(-5, 5),\n",
    "            shear=(-3, 3),\n",
    "        ),\n",
    "        iaa.PiecewiseAffine(scale=(0.002, 0.03)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.85, 1.15)),\n",
    "        iaa.ContrastNormalization((0.85, 1.15)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.12)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.12)),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# test augmentation on the same sample image as above\n",
    "imggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\n",
    "plt.figure(figsize=(30, 12))\n",
    "_ = plt.imshow(imggrid[:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rEgJaXwef70"
   },
   "outputs": [],
   "source": [
    "# training the mask RCNN model using the config specified previously\n",
    "\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6-jp84leh_O"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# first epochs with higher lr to speedup the learning\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE*2,\n",
    "            epochs=2,\n",
    "            layers='all',\n",
    "            augmentation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0q8lUE_elFU"
   },
   "outputs": [],
   "source": [
    "# Including image augmentation to improve performance\n",
    "# Reducing the learning rate to improve on performance\n",
    "\n",
    "%%time\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKMzDcGUeoVx"
   },
   "source": [
    "### Model Evaluation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvmzHgRoerdG"
   },
   "outputs": [],
   "source": [
    "# Visualising a few examples of ground truth vs. predictions\n",
    "# on the validation dataset\n",
    "\n",
    "dataset = dataset_val\n",
    "fig = plt.figure(figsize=(10, 30))\n",
    "\n",
    "for i in range(6):\n",
    "    image_id = random.choice(dataset.image_ids)\n",
    "\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask = \\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "    print(original_image.shape)\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                                dataset.class_names,\n",
    "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
    "\n",
    "    plt.subplot(6, 2, 2*i + 2)\n",
    "    results = model.detect([original_image]) #, verbose=1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "                                dataset.class_names, r['scores'],\n",
    "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmPlWEJrewH-"
   },
   "outputs": [],
   "source": [
    "# Get filenames of test dataset DICOM images\n",
    "test_image_fps = get_dicom_fps(test_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-8SxblCeycX"
   },
   "outputs": [],
   "source": [
    "# Visualising a few images from the test data directory and the\n",
    "# the predicted bounding boxes for them\n",
    "\n",
    "def visualize():\n",
    "    image_id = random.choice(test_image_fps)\n",
    "    ds = pydicom.read_file(image_id)\n",
    "\n",
    "    # original image\n",
    "    image = ds.pixel_array\n",
    "\n",
    "    # assume square image\n",
    "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "        image = np.stack((image,) * 3, -1)\n",
    "    resized_image, window, scale, padding, crop = utils.resize_image(\n",
    "        image,\n",
    "        min_dim=config.IMAGE_MIN_DIM,\n",
    "        min_scale=config.IMAGE_MIN_SCALE,\n",
    "        max_dim=config.IMAGE_MAX_DIM,\n",
    "        mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "    patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "    print(patient_id)\n",
    "\n",
    "    results = model.detect([resized_image])\n",
    "    r = results[0]\n",
    "    for bbox in r['rois']:\n",
    "        print(bbox)\n",
    "        x1 = int(bbox[1] * resize_factor)\n",
    "        y1 = int(bbox[0] * resize_factor)\n",
    "        x2 = int(bbox[3] * resize_factor)\n",
    "        y2 = int(bbox[2]  * resize_factor)\n",
    "        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap=plt.cm.gist_gray)\n",
    "\n",
    "visualize()\n",
    "visualize()\n",
    "visualize()\n",
    "visualize()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
